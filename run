#!/bin/bash
#
# Copyright (c) 2020-2021, NVIDIA CORPORATION.
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

init_globals() {
    if [ "$0" != "/bin/bash" ]; then
        SCRIPT_DIR=$(dirname "$(readlink -f "$0")")
        export RUN_SCRIPT_FILE="$(readlink -f "$0")"
    else
        export RUN_SCRIPT_FILE="$(readlink -f "${BASH_SOURCE[0]}")"
    fi

    export TOP=$(git rev-parse --show-toplevel || $(dirname "${RUN_SCRIPT_FILE}"))
}

################################################################################
# Utility functions
################################################################################

#######################################
# Get list of available commands from a given input file.
#
# Available commands and command summary are extracted by checking a pattern
# "_desc() { echo '".
# Section title is extracted by checking a pattern "# Section: ".
# This command is used for listing available commands in CLI.
#
# e.g.)
#   "# Section: String/IO functions"
#     => "# String/IO functions"
#   "to_lower_desc() { echo 'Convert to lower case"
#     => "to_lower ----------------- Convert to lower case"
#
# Arguments:
#   $1 - input file that defines commands
# Returns:
#   Print list of available commands from $1
#######################################
get_list_of_available_commands() {
    local file_name="$1"
    if [ ! -e "$1" ]; then
        echo "$1 doesn't exist!"
    fi

    local line_str='--------------------------------'
    local IFS= cmd_lines="$(IFS= cat "$1" | grep -E -e "^(([[:alpha:]_[:digit:]]+)_desc\(\)|# Section: )" | sed "s/_desc() *{ *echo '/ : /")"
    local line
    while IFS= read -r line; do
        local cmd=$(echo "$line" | cut -d":" -f1)
        local desc=$(echo "$line" | cut -d":" -f2-)
        if [ "$cmd" = "# Section" ]; then
            c_echo B "${desc}"
        else
            # there is no substring operation in 'sh' so use 'cut'
            local dash_line="$(echo "${line_str}" | cut -c ${#cmd}-)"  #  = "${line_str:${#cmd}}"
             c_echo Y "   ${cmd}" w " ${dash_line} ${desc}"
        fi
        # use <<EOF, not '<<<"$cmd_lines"' to be executable in sh
    done <<EOF
$cmd_lines
EOF
}

my_cat_prefix() {
    local IFS
    local prefix="$1"
    local line
    while IFS= read -r line; do
        echo "${prefix}${line}" # -e option doesn't work in 'sh' so disallow escaped characters
    done <&0
}


c_str() {
    local old_color=39
    local old_attr=0
    local color=39
    local attr=0
    local text=""
    #local no_change=0
    for i in "$@"; do
        case "$i" in
            r|R)
                color=31
                ;;
            g|G)
                color=32
                ;;
            y|Y)
                color=33
                ;;
            b|B)
                color=34
                ;;
            p|P)
                color=35
                ;;
            c|C)
                color=36
                ;;
            w|W)
                color=37
                ;;

            z|Z)
                color=0
                ;;
        esac
        case "$i" in
            l|L|R|G|Y|B|P|C|W)
                attr=1
                ;;
            n|N|r|g|y|b|p|c|w)
                attr=0
                ;;
            z|Z)
                attr=0
                ;;
            *)
                text="${text}$i"
        esac
        if [ ${old_color} -ne ${color} ] || [ ${old_attr} -ne ${attr} ]; then
            text="${text}\033[${attr};${color}m"
            old_color=$color
            old_attr=$attr
        fi
    done
    /bin/echo -en "$text"
}

c_echo() {
    local old_opt="$(shopt -op xtrace)" # save old xtrace option
    set +x # unset xtrace
    local text="$(c_str "$@")"
    /bin/echo -e "$text\033[0m"
    eval "${old_opt}" # restore old xtrace option
}


echo_err() {
    >&2 echo "$@"
}

c_echo_err() {
    >&2 c_echo "$@"
}

printf_err() {
    >&2 printf "$@"
}

get_item_ranges() {
    local indexes="$1"
    local list="$2"
    echo -n "$(echo "${list}" | xargs | cut -d " " -f "${indexes}")"
    return $?
}

get_unused_ports() {
    local num_of_ports=${1:-1}
    local start=${2:-49152}
    local end=${3:-61000}
    comm -23 \
    <(seq ${start} ${end} | sort) \
    <(ss -tan | awk '{print $4}' | while read line; do echo ${line##*\:}; done | grep '[0-9]\{1,5\}' | sort -u) \
    | shuf | tail -n ${num_of_ports} # use tail instead head to avoid broken pipe in VSCode terminal
}

newline() {
    echo
}

info() {
    c_echo W "$(date -u '+%Y-%m-%d %H:%M:%S') [INFO] " Z "$@"
}

error() {
    echo R "$(date -u '+%Y-%m-%d %H:%M:%S') [ERROR] " Z "$@"
}

fatal() {
    echo R "$(date -u '+%Y-%m-%d %H:%M:%S') [FATAL] " Z "$@"
    echo
    if [ -n "${SCRIPT_DIR}" ]; then
        exit 1
    fi
}

run_command() {
    local status=0
    local cmd="$*"

    c_echo B "$(date -u '+%Y-%m-%d %H:%M:%S') " W "\$ " G "${cmd}"

    [ "$(echo -n "$@")" = "" ] && return 1 # return 1 if there is no command available

    "$@"
    status=$?

    unset IFS

    return $status
}

retry() {
    local retries=$1
    shift

    local count=0
    until run_command "$@"; do
        exit=$?
        wait=$((2 ** count))
        count=$((count + 1))
        if [ $count -lt $retries ]; then
            info "Retry $count/$retries. Exit code=$exit, Retrying in $wait seconds..."
            sleep $wait
        else
            fatal "Retry $count/$retries. Exit code=$exit, no more retries left."
            return 1
        fi
    done
    return 0
}

#==================================================================================
# Section: Build
#==================================================================================

build_manylinux2014_desc() { echo 'Build manylinux2014 image

Arguments:
  $1 - cuda version (e.g., 110, 111)
'
}
build_manylinux2014() {
    local cuda_version="${1:-110}"
    run_command docker build -f ${TOP}/Dockerfile-cuda${cuda_version} -t gigony/manylinux2014-x64:cuda${cuda_version} ${TOP}

    read -n 1 -r -p "$(c_str R "Do you want to update dockcross-manylinux2014-x64 with " G "cuda${cuda_version}" R " (y/n)?")"
    echo
    if [[ $REPLY =~ ^[Yy]$ ]]; then
        sed -i -e "s/manylinux2014-x64:cuda.../manylinux2014-x64:cuda${cuda_version}/g" ${TOP}/dockcross-manylinux2014-x64
        c_echo W "Done"
    fi
}

build_local_libcucim_() {
    local source_folder=${1:-${TOP}}
    local build_type=${2:-debug}
    local build_type_str=${3:-Debug}
    local prefix=${4:-}
    local build_folder=${source_folder}/build-${build_type}
    local CMAKE_CMD=${CMAKE_CMD:-cmake}

    pushd ${source_folder} > /dev/null

    # Copy cufile SDK from host system to temp/cuda
    copy_gds_files_ $source_folder
    # Copy libjpeg SDK from host system to temp/cuda
    copy_nvjpeg_files_ $source_folder

    ${CMAKE_CMD} -S ${source_folder} -B ${build_folder} -G "Unix Makefiles" \
        -DCMAKE_EXPORT_COMPILE_COMMANDS:BOOL=TRUE \
        -DCMAKE_PREFIX_PATH=${prefix} \
        -DCMAKE_BUILD_TYPE=${build_type_str} \
        -DCMAKE_INSTALL_PREFIX=${source_folder}/install
    ${CMAKE_CMD} --build ${build_folder} --config ${build_type_str} --target cucim -- -j $(nproc)
    ${CMAKE_CMD} --build ${build_folder} --config ${build_type_str} --target install -- -j $(nproc)

    popd
}

build_local_cuslide_() {
    local source_folder=${1:-${TOP}/cpp/plugins/cucim.kit.cuslide}
    local build_type=${2:-debug}
    local build_type_str=${3:-Debug}
    local prefix=${4:-}
    local build_folder=${source_folder}/build-${build_type}
    local CMAKE_CMD=${CMAKE_CMD:-cmake}

    pushd ${source_folder} > /dev/null

    ${CMAKE_CMD} -S ${source_folder} -B ${build_folder} -G "Unix Makefiles" \
        -DCMAKE_EXPORT_COMPILE_COMMANDS:BOOL=TRUE \
        -DCMAKE_BUILD_TYPE=${build_type_str} \
        -DCMAKE_PREFIX_PATH=${prefix} \
        -DCMAKE_INSTALL_PREFIX=${source_folder}/install
    ${CMAKE_CMD} --build ${build_folder} --config ${build_type_str} --target cucim.kit.cuslide -- -j $(nproc)
    ${CMAKE_CMD} --build ${build_folder} --config ${build_type_str} --target install -- -j $(nproc)

    popd
}

build_local_cumed_() {
    local source_folder=${1:-${TOP}/cpp/plugins/cucim.kit.cumed}
    local build_type=${2:-debug}
    local build_type_str=${3:-Debug}
    local prefix=${4:-}
    local build_folder=${source_folder}/build-${build_type}
    local CMAKE_CMD=${CMAKE_CMD:-cmake}

    pushd ${source_folder} > /dev/null

    ${CMAKE_CMD} -S ${source_folder} -B ${build_folder} -G "Unix Makefiles" \
        -DCMAKE_EXPORT_COMPILE_COMMANDS:BOOL=TRUE \
        -DCMAKE_BUILD_TYPE=${build_type_str} \
        -DCMAKE_PREFIX_PATH=${prefix} \
        -DCMAKE_INSTALL_PREFIX=${source_folder}/install
    ${CMAKE_CMD} --build ${build_folder} --config ${build_type_str} --target cucim.kit.cumed -- -j $(nproc)
    ${CMAKE_CMD} --build ${build_folder} --config ${build_type_str} --target install -- -j $(nproc)

    popd
}

build_local_cucim_() {
    local source_folder=${1:-${TOP}/python}
    local build_type=${2:-debug}
    local build_type_str=${3:-Debug}
    local prefix=${4:-}
    local build_folder=${source_folder}/build-${build_type}
    local CMAKE_CMD=${CMAKE_CMD:-cmake}

    pushd ${source_folder} > /dev/null

    local python_library=$(python3 -c "import distutils.sysconfig as sysconfig, os; print(os.path.join(sysconfig.get_config_var('LIBDIR'), sysconfig.get_config_var('LDLIBRARY')))")
    local python_include_dir=$(python3 -c "from distutils.sysconfig import get_python_inc; print(get_python_inc())")

    ${CMAKE_CMD} -S ${source_folder} -B ${build_folder} -G "Unix Makefiles" \
        -DCMAKE_EXPORT_COMPILE_COMMANDS:BOOL=TRUE \
        -DCMAKE_BUILD_TYPE=${build_type_str} \
        -DCMAKE_PREFIX_PATH=${prefix} \
        -DCMAKE_INSTALL_PREFIX=${source_folder}/install \
        -DPYTHON_EXECUTABLE=$(which python3) \
        -DPYTHON_LIBRARY=${python_library} \
        -DPYTHON_INCLUDE_DIR=${python_include_dir}
    ${CMAKE_CMD} --build ${build_folder} --config ${build_type_str} --target cucim -- -j $(nproc)
    ${CMAKE_CMD} --build ${build_folder} --config ${build_type_str} --target install -- -j $(nproc)

    popd
}

build_local_desc() { echo 'Build locally

Compile binaries locally

Arguments:
  $1 - subcommand [all|clean_cache|clean|libcucim|cuslide|cumed|cucim] (default: all)
  $2 - build type [debug|release|rel-debug] (default: debug)
'
}
build_local() {
    local subcommand="${1:-all}"
    local build_type="${2:-debug}"
    local build_type_str="Debug"
    local prefix=${3:-}

    local major_version="$(cat ${TOP}/VERSION | cut -d. -f1)" # major version number

    [ "$build_type" = "debug" ] && build_type_str="Debug"
    [ "$build_type" = "release" ] && build_type_str="Release"
    [ "$build_type" = "rel-debug" ] && build_type_str="RelWithDebInfo"

    local old_opt="$(shopt -op errexit);$(shopt -op nounset)" # save old shopts
    set -eu

    if [ "$subcommand" = "clean_cache" ]; then
        rm -f ${TOP}/build-*/CMakeCache.txt
        rm -f ${TOP}/cpp/plugins/cucim.kit.cuslide/build-*/CMakeCache.txt
        rm -f ${TOP}/cpp/plugins/cucim.kit.cumed/build-*/CMakeCache.txt
        rm -f ${TOP}/python/build-*/CMakeCache.txt
    fi

    if [ "$subcommand" = "clean" ]; then
        rm -rf ${TOP}/build-*
        rm -rf ${TOP}/install
        rm -rf ${TOP}/cpp/plugins/cucim.kit.cuslide/build-*/
        rm -rf ${TOP}/cpp/plugins/cucim.kit.cuslide/install
        rm -rf ${TOP}/cpp/plugins/cucim.kit.cumed/build-*/
        rm -rf ${TOP}/cpp/plugins/cucim.kit.cumed/install
        rm -rf ${TOP}/python/build-*
        rm -rf ${TOP}/python/install
    fi

    if [ "$subcommand" = "all" ] || [ "$subcommand" = "libcucim" ]; then
        build_local_libcucim_ ${TOP} ${build_type} ${build_type_str} ${prefix}
    fi

    if [ "$subcommand" = "all" ] || [ "$subcommand" = "cuslide" ]; then
        build_local_cuslide_ ${TOP}/cpp/plugins/cucim.kit.cuslide ${build_type} ${build_type_str} ${prefix}
    fi

    if [ "$subcommand" = "all" ] || [ "$subcommand" = "cumed" ]; then
        build_local_cumed_ ${TOP}/cpp/plugins/cucim.kit.cumed ${build_type} ${build_type_str} ${prefix}
    fi

    if [ "$subcommand" = "all" ] || [ "$subcommand" = "cucim" ]; then
        build_local_cucim_ ${TOP}/python ${build_type} ${build_type_str} ${prefix}
    fi

    # Remove existing library files at python/cucim/src/cucim/clara
    rm -f ${TOP}/python/cucim/src/cucim/clara/*.so*

    if [ "$subcommand" = "all" ] || [ "$subcommand" = "cucim" ]; then
        # We don't need to copy binary if executed by conda-build
        if [ "${CONDA_BUILD:-}" != "1" ]; then
            # Copy .so files from libcucim & cuslide/cumed's build folders to cuCIM's Python source folder
            # Since wheel file doesn't support symbolic link (https://github.com/pypa/wheel/issues/203),
            # we don't need to copy symbolic links. Instead copy only libcucim.so.${major_version} (without symbolic link)
            cp ${TOP}/build-$build_type/lib*/libcucim.so.${major_version} ${TOP}/python/cucim/src/cucim/clara/
            cp -P ${TOP}/cpp/plugins/cucim.kit.cuslide/build-$build_type/lib*/cucim* ${TOP}/python/cucim/src/cucim/clara/
            cp -P ${TOP}/cpp/plugins/cucim.kit.cumed/build-$build_type/lib*/cucim* ${TOP}/python/cucim/src/cucim/clara/

            # Copy .so files from pybind's build folder to cuCIM's Python source folder
            cp ${TOP}/python/build-$build_type/lib/cucim/_cucim.*.so ${TOP}/python/cucim/src/cucim/clara/
        fi
    fi

    eval "${old_opt}" # restore old shopts
}

copy_gds_files_() {
    local root_folder=${1:-${TOP}}
    local cufile_search="${root_folder}/temp/cuda/include:${root_folder}/temp/cuda/lib64"  #"/usr/local/cuda/include:/usr/local/cuda/lib64 ${PREFIX:-}/include:${PREFIX:-}/lib ${CONDA_PREFIX:-}/include:${CONDA_PREFIX:-}/lib ${root_folder}/temp/cuda/include:${root_folder}/temp/cuda/lib64"
    local gds_version=1.0.0
    local candidate
    local cufile_include
    local cufile_lib

    for candidate in ${cufile_search}; do
        cufile_include="$(echo $candidate | cut -d: -f1)"
        cufile_lib="$(echo $candidate | cut -d: -f2)"
        if [ -f ${cufile_include}/cufile.h ] && [ -f ${cufile_lib}/libcufile.so ]; then
            c_echo W "GDS client library is available at '${cufile_include}/cufile.h' and '${cufile_lib}/libcufile.so'"
            break
        fi
        cufile_include=""
        cufile_lib=""
    done

    if [ ! -f ${cufile_include}/cufile.h ]; then
        c_echo_err Y "GDS client library is not available! Downloading the redistributable package to get cufile.h and libraries."

        run_command rm -rf ${root_folder}/temp/cuda
        run_command mkdir -p ${root_folder}/temp/cuda/include ${root_folder}/temp/cuda/lib64

        local temp_tgz_dir=$(mktemp -d)
        pushd ${temp_tgz_dir}
        run_command wget https://developer.download.nvidia.com/gds/redist/rel-${gds_version}/gds-redistrib-${gds_version}.tgz
        run_command tar xzvf gds-redistrib-${gds_version}.tgz
        run_command cp -P gds-redistrib-${gds_version}/targets/x86_64-linux/include/cufile.h ${root_folder}/temp/cuda/include/
        run_command cp -P gds-redistrib-${gds_version}/targets/x86_64-linux/lib/* ${root_folder}/temp/cuda/lib64/
        popd > /dev/null
        run_command rm -r ${temp_tgz_dir}
    else
        run_command mkdir -p ${root_folder}/temp/cuda/include ${root_folder}/temp/cuda/lib64

        if [ "${cufile_include}" != "${root_folder}/temp/cuda/include" ]; then
            run_command cp -Pf ${cufile_include}/cufile.h ${root_folder}/temp/cuda/include/ || true
            run_command cp -Pf ${cufile_lib}/libcufile* ${root_folder}/temp/cuda/lib64/ || true
        fi
    fi
}

get_arch_name_() {
    architecture="unknown"
    case $(uname -m) in
        x86_64) architecture="x86_64" ;;
        arm|aarch64)    dpkg --print-architecture | grep -q "arm64" && architecture="sbsa";;
    esac
    echo "${architecture}"
}

copy_nvjpeg_files_() {
    local root_folder=${1:-${TOP}}
    local arch_name="$(get_arch_name_)"
    local nvjpeg_search="${root_folder}/temp/cuda/include:${root_folder}/temp/cuda/lib64"
    local cuda_version="11.5"
    local nvjpeg_version="11-5_11.5.4.107-1"
    local candidate
    local nvjpeg_include
    local nvjpeg_lib

    # TODO: Do not copy nvjpeg files until device input is supported (CUDA 11.6)
    return

    for candidate in ${nvjpeg_search}; do
        nvjpeg_include="$(echo $candidate | cut -d: -f1)"
        nvjpeg_lib="$(echo $candidate | cut -d: -f2)"
        if [ -f ${nvjpeg_include}/cufile.h ] && [ -f ${nvjpeg_lib}/libcufile.so ]; then
            c_echo W "GDS client library is available at '${nvjpeg_include}/cufile.h' and '${nvjpeg_lib}/libcufile.so'"
            break
        fi
        nvjpeg_include=""
        nvjpeg_lib=""
    done

    if [ ! -f ${nvjpeg_include}/nvjpeg.h ]; then
        c_echo_err Y "nvJPEG library is not available! Downloading the redistributable package to get nvjpeg.h and libraries."

        run_command rm -rf ${root_folder}/temp/cuda/include/*nvjpeg*
        run_command rm -rf ${root_folder}/temp/cuda/lib64/*nvjpeg*
        run_command mkdir -p ${root_folder}/temp/cuda/include ${root_folder}/temp/cuda/lib64

        local temp_tgz_dir=$(mktemp -d)
        pushd ${temp_tgz_dir}
        c_echo W "Arch name: " G "${arch_name}"
        if [ "${arch_name}" = "sbsa" ]; then
            run_command wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/${arch_name}/libnvjpeg-dev-${nvjpeg_version}_arm64.deb
        else
            run_command wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/${arch_name}/libnvjpeg-dev-${nvjpeg_version}_amd64.deb
        fi
        mkdir -p libnvjpeg-dev
        run_command ar x libnvjpeg-dev-${nvjpeg_version}*.deb --output=libnvjpeg-dev
        pushd libnvjpeg-dev > /dev/null
        run_command xz --decompress data.tar.xz
        run_command tar xvf data.tar
        popd > /dev/null

        run_command cp libnvjpeg-dev/usr/local/cuda-${cuda_version}/include/nvjpeg.h ${root_folder}/temp/cuda/include/
        run_command cp libnvjpeg-dev/usr/local/cuda-${cuda_version}/lib64/libnvjpeg_static.a ${root_folder}/temp/cuda/lib64/
        popd > /dev/null
        run_command rm -r ${temp_tgz_dir}
    else
        run_command mkdir -p ${root_folder}/temp/cuda/include ${root_folder}/temp/cuda/lib64

        if [ "${nvjpeg_include}" != "${root_folder}/temp/cuda/include" ]; then
            run_command cp -Pf ${nvjpeg_include}/*nvjpeg* ${root_folder}/temp/cuda/include/ || true
            run_command cp -Pf ${nvjpeg_lib}/*nvjpeg* ${root_folder}/temp/cuda/lib64/ || true
        fi
    fi
}

build_python_package_desc() { echo 'Build Python package

Note: This command does not remove `dist` folder before building.
'
}
build_python_package() {
    local ret=0
    local old_opt="$(shopt -op errexit);$(shopt -op nounset)" # save old shopts
    set -eu

    # Copy cufile SDK from host system to temp/cuda
    copy_gds_files_
    # Copy nvjpeg SDK from host system to temp/cuda
    copy_nvjpeg_files_

    run_command ${TOP}/dockcross-manylinux2014-x64 ./run build_python_package_
    ret=$?

    eval "${old_opt}" # restore old shopts

    return ${ret}
}

repair_wheel_() {
    local wheel="$1"
    local dest="${2:-./}"
    local PLAT="${3:-manylinux2014_x86_64}"


    if ! auditwheel show "$wheel"; then
        echo "Skipping non-platform wheel ${wheel}"
    else
        $(head -1 $(which auditwheel) | cut -d'!' -f2) $TOP/scripts/auditwheel_repair.py repair --plat "${PLAT}" -w ${dest} "${wheel}"
    fi
}

build_python_package_() {
    local SRC_ROOT=${1:-${TOP}}
    local BUILD_ROOT=${2:-${TOP}/temp}
    local DEST_ROOT=${3:-${TOP}/dist}
    local CUCIM_SDK_PATH=${4:-${BUILD_ROOT}/libcucim}

    local old_opt="$(shopt -op errexit);$(shopt -op nounset)" # save old shopts
    local major_version="$(cat ${TOP}/VERSION | cut -d. -f1)" # major version number
    set -eu

    # Clear CMakeCache.txt to use the latest options
    run_command rm -f ${BUILD_ROOT}/libcucim/CMakeCache.txt
    run_command rm -f ${BUILD_ROOT}/cuslide/CMakeCache.txt
    run_command rm -f ${BUILD_ROOT}/cumed/CMakeCache.txt
    run_command rm -f ${BUILD_ROOT}/cucim/CMakeCache.txt

    # Create a folder for .whl file that repair_wheel_ is not applied.
    TEMP_PYPKG_DIR=${BUILD_ROOT}/py_pkg # $(mktemp -d)
    c_echo b "TEMP_PYPKG_DIR=${TEMP_PYPKG_DIR}"
    mkdir -p $TEMP_PYPKG_DIR
    rm -rf $TEMP_PYPKG_DIR/*
    # trap 'rm -rf ${TEMP_PYPKG_DIR}' EXIT

    local CMAKE_CMD=${CMAKE_CMD:-cmake}
    local CMAKE_BUILD_TYPE=${CMAKE_BUILD_TYPE:-Release}
    local NUM_THREADS=${NUM_THREADS:-$(nproc)}

    local PLAT=manylinux2014_x86_64

    local pybins

    mkdir -p ${DEST_ROOT}

    # Remove existing library files at build root
    rm -rf ${BUILD_ROOT}/libcucim/lib/*
    rm -rf ${BUILD_ROOT}/libcucim/install/lib*/lib*
    rm -rf ${BUILD_ROOT}/cuslide/lib/*
    rm -rf ${BUILD_ROOT}/cuslide/install/lib*/cucim*
    rm -rf ${BUILD_ROOT}/cumed/lib/*
    rm -rf ${BUILD_ROOT}/cumed/install/lib*/cucim*
    rm -rf ${BUILD_ROOT}/cucim/lib/cucim/*.so*
    rm -rf ${BUILD_ROOT}/cucim/install/lib/*.so*

    # Build libcucim
    ${CMAKE_CMD} -S ${SRC_ROOT} -B ${BUILD_ROOT}/libcucim \
        -DCMAKE_BUILD_TYPE=${CMAKE_BUILD_TYPE} \
        -DCMAKE_INSTALL_PREFIX=${CUCIM_SDK_PATH}/install
    ${CMAKE_CMD} --build ${BUILD_ROOT}/libcucim --config ${CMAKE_BUILD_TYPE} --target cucim -- -j ${NUM_THREADS}
    ${CMAKE_CMD} --build ${BUILD_ROOT}/libcucim --config ${CMAKE_BUILD_TYPE} --target install -- -j ${NUM_THREADS}

    # Build cuslide plugin
    ${CMAKE_CMD} -S ${SRC_ROOT}/cpp/plugins/cucim.kit.cuslide -B ${BUILD_ROOT}/cuslide \
        -DCMAKE_BUILD_TYPE=${CMAKE_BUILD_TYPE} \
        -DCMAKE_INSTALL_PREFIX=${BUILD_ROOT}/cuslide/install \
        -DCUCIM_SDK_PATH=${CUCIM_SDK_PATH}
    ${CMAKE_CMD} --build ${BUILD_ROOT}/cuslide --config ${CMAKE_BUILD_TYPE} --target cucim.kit.cuslide -- -j ${NUM_THREADS}
    ${CMAKE_CMD} --build ${BUILD_ROOT}/cuslide --config ${CMAKE_BUILD_TYPE} --target install -- -j ${NUM_THREADS}

    # Build cumed plugin
    ${CMAKE_CMD} -S ${SRC_ROOT}/cpp/plugins/cucim.kit.cumed -B ${BUILD_ROOT}/cumed \
        -DCMAKE_BUILD_TYPE=${CMAKE_BUILD_TYPE} \
        -DCMAKE_INSTALL_PREFIX=${BUILD_ROOT}/cumed/install \
        -DCUCIM_SDK_PATH=${CUCIM_SDK_PATH}
    ${CMAKE_CMD} --build ${BUILD_ROOT}/cumed --config ${CMAKE_BUILD_TYPE} --target cucim.kit.cumed -- -j ${NUM_THREADS}
    ${CMAKE_CMD} --build ${BUILD_ROOT}/cumed --config ${CMAKE_BUILD_TYPE} --target install -- -j ${NUM_THREADS}

    # Build Python bind
    pybins="$(echo /opt/python/*/bin)"
    if [ "${pybins}" = "/opt/python/*/bin" ]; then
        pybins="$(dirname $(which python3))" # for building at host
    fi
    for PYBIN in ${pybins}; do
        local python_library=$(${PYBIN}/python3 -c "import distutils.sysconfig as sysconfig; import os; print(os.path.join(sysconfig.get_config_var('LIBDIR'), sysconfig.get_config_var('LDLIBRARY')))")
        local python_include_dir=$(${PYBIN}/python3 -c "from distutils.sysconfig import get_python_inc; print(get_python_inc())")

        ${CMAKE_CMD} -S ${SRC_ROOT}/python -B ${BUILD_ROOT}/cucim \
            -DCMAKE_BUILD_TYPE=${CMAKE_BUILD_TYPE} \
            -DCMAKE_INSTALL_PREFIX=${BUILD_ROOT}/cucim/install \
            -DCUCIM_SDK_PATH=${CUCIM_SDK_PATH} \
            -DPYTHON_EXECUTABLE=${PYBIN}/python3 \
            -DPYTHON_LIBRARY=${python_library} \
            -DPYTHON_INCLUDE_DIR=${python_include_dir}
        ${CMAKE_CMD} --build ${BUILD_ROOT}/cucim --config ${CMAKE_BUILD_TYPE} --target cucim -- -j ${NUM_THREADS}
        ${CMAKE_CMD} --build ${BUILD_ROOT}/cucim --config ${CMAKE_BUILD_TYPE} --target install -- -j ${NUM_THREADS}
    done

    # Remove existing library files at python/cucim/src/cucim/clara
    rm -f ${SRC_ROOT}/python/cucim/src/cucim/clara/*.so*

    # Copy .so files to pybind's build folder
    # (it uses -P to copy symbolic links as they are)
    cp -P ${BUILD_ROOT}/libcucim/install/lib*/lib* ${BUILD_ROOT}/cucim/install/lib/
    cp -P ${BUILD_ROOT}/cuslide/install/lib*/cucim* ${BUILD_ROOT}/cucim/install/lib/
    cp -P ${BUILD_ROOT}/cumed/install/lib*/cucim* ${BUILD_ROOT}/cucim/install/lib/

    # Copy .so files from pybind's build folder to cucim Python source folder
    # Since wheel file doesn't support symbolic link (https://github.com/pypa/wheel/issues/203),
    # we don't need to copy symbolic links. Instead copy only libcucim.so.${major_version} (without symbolic link)
      #find ${BUILD_ROOT}/cucim/install/lib -maxdepth 1 -type f -exec cp {} ${SRC_ROOT}/python/cucim/src/cucim/clara/ \;
    cp ${BUILD_ROOT}/cucim/install/lib/_cucim.*.so ${SRC_ROOT}/python/cucim/src/cucim/clara/
    cp ${BUILD_ROOT}/cucim/install/lib/cucim.*.so ${SRC_ROOT}/python/cucim/src/cucim/clara/
    cp ${BUILD_ROOT}/cucim/install/lib/libcucim.so.${major_version} ${SRC_ROOT}/python/cucim/src/cucim/clara/
    find ${BUILD_ROOT}/cucim/install/lib -maxdepth 1 -type f -name "lib*.so" -exec cp {} ${SRC_ROOT}/python/cucim/src/cucim/clara/ \;

    cd ${SRC_ROOT}/python/cucim

    # Remove build folder
    rm -rf ${SRC_ROOT}/python/cucim/build
    # Compile wheels (one python binary is enough)
    pybins="$(echo /opt/python/*/bin)"
    [ ! -e /opt/python/cp36-cp36m/bin ] && pybins="$(dirname $(which python3))" # for building at host

    pybins="$(echo /opt/python/*/bin)"
    if [ "${pybins}" = "/opt/python/*/bin" ]; then # if multiple python binaries not found
        pybins="$(dirname $(which python3))" # for building at host
    else
        pybins=/opt/python/cp36-cp36m/bin # use Python 3.6 for executing setup.py
    fi

    for PYBIN in ${pybins}; do # /opt/python/*/bin
        run_command "${PYBIN}/python3" setup.py bdist_wheel -p $PLAT -d ${TEMP_PYPKG_DIR}
    done

    # Do not bundle external shared libraries for now.
    # (CUDA-related libraries cannot be redistributed without EULA messages confirmed by user)
    # Here, we just copy to dist folder.
    # cp ${TEMP_PYPKG_DIR}/*.whl ${DEST_ROOT}/

    # Bundle external shared libraries into the wheels
    for whl in ${TEMP_PYPKG_DIR}/*.whl; do
        repair_wheel_ "$whl" "${DEST_ROOT}/" "${PLAT}"
    done

    # run_command rm -rf ${TEMP_PYPKG_DIR}
    # trap -- EXIT

    # Copy cpp packages and examples
    mkdir -p ${DEST_ROOT}/examples/cpp
    cp -P -r ${BUILD_ROOT}/libcucim/install ${DEST_ROOT}/
    cp -P -r ${BUILD_ROOT}/cuslide/install/lib/*.so ${DEST_ROOT}/install/lib/
    cp -P -r ${BUILD_ROOT}/cumed/install/lib/*.so ${DEST_ROOT}/install/lib/
    cp -r ${SRC_ROOT}/examples/cpp/tiff_image ${DEST_ROOT}/examples/cpp/

    cp ${BUILD_ROOT}/libcucim/CMakeLists.txt.examples.release ${DEST_ROOT}/examples/cpp/CMakeLists.txt

    # # Install packages and test
    # for PYBIN in /opt/python/*/bin/; do
    #     "${PYBIN}/pip" install python-manylinux-demo --no-index -f /io/wheelhouse
    #     (cd "$HOME"; "${PYBIN}/nosetests" pymanylinuxdemo)
    # done
    # python setup.py bdist_wheel -p manylinux2014-x86_64

    eval "${old_opt}" # restore old shopts
}

build_package_desc() { echo 'Build package for release (& gen_docs)
'
}
build_package() {
    local SRC_ROOT=${1:-${TOP}}
    local BUILD_ROOT=${2:-${TOP}/temp}
    local DEST_ROOT=${3:-${TOP}/dist}
    local CUCIM_SDK_PATH=${4:-${BUILD_ROOT}/libcucim}

    # Clean dist folder
    mkdir -p ${DEST_ROOT}
    [ -n "${DEST_ROOT}" ] && run_command sudo rm -rf ${DEST_ROOT}/*

    build_python_package ${SRC_ROOT} ${BUILD_ROOT} ${DEST_ROOT} ${CUCIM_SDK_PATH}
    gen_docs ${DEST_ROOT}/docs
    copy_data_ ${SRC_ROOT} ${BUILD_ROOT} ${DEST_ROOT}

    # Copy the built wheel file into ${TOP}/notebooks
    run_command cp ${DEST_ROOT}/*.whl ${TOP}/notebooks/
}

copy_data_() {
    c_echo W "Copy necessary files for packaging..."
    local SRC_ROOT=${1:-${TOP}}
    local BUILD_ROOT=${2:-${TOP}/temp}
    local DEST_ROOT=${3:-${TOP}/dist}

    # Create notebooks folder (add notebooks and scripts)
    run_command mkdir -p ${DEST_ROOT}/notebooks/static_images
    run_command cp $(git ls-files ${SRC_ROOT}/notebooks/*.ipynb) ${DEST_ROOT}/notebooks/
    run_command cp ${SRC_ROOT}/notebooks/static_images/*.png ${DEST_ROOT}/notebooks/static_images/

    # Create docker folder
    run_command mkdir -p ${DEST_ROOT}/docker
    run_command cp ${SRC_ROOT}/docker/*-jupyter{,-gds,.txt} ${DEST_ROOT}/docker/
    run_command cp ${SRC_ROOT}/docker/*-claratrain{,.txt} ${DEST_ROOT}/docker/
    run_command cp ${SRC_ROOT}/docker/*-cmake ${DEST_ROOT}/docker/
    run_command cp ${SRC_ROOT}/docker/cufile.json ${DEST_ROOT}/docker/ # Copy cufile.json

    # Copy main script
    run_command cp ${SRC_ROOT}/scripts/run-dist ${DEST_ROOT}/run

    # Create .dockerignore to speed up docker run
    echo "notebooks" > ${DEST_ROOT}/.dockerignore

    # Copy license files
    run_command cp -r ${SRC_ROOT}/3rdparty ${SRC_ROOT}/LICENSE* ${DEST_ROOT}/
}


#==================================================================================
# Section: Test
#==================================================================================

test_desc() { echo 'Execute test cases

Arguments:
  $1 - subcommand [all|python|c++] (default: all)
  $2 - test_type [all|unit|integration|system|performance] (default: all)
  $3 - test_component [all|clara|skimage] (default: all)
'
}
test() {
    local subcommand="${1:-all}"
    local test_type="${2:-all}"
    shift;

    if [ "$subcommand" = "all" ] || [ "$subcommand" = "python" ]; then
        test_python "$@"
    fi
}

install_python_test_deps_() {
    if [ -n "${CONDA_PREFIX}" ]; then
        run_command conda install -c conda-forge -y \
            --file ${TOP}/python/cucim/requirements-test.txt
    else
        if [ -n "${VIRTUAL_ENV}" ]; then
            run_command pip3 install -r ${TOP}/python/cucim/requirements-test.txt
        else
            run_command pip3 install --user -r ${TOP}/python/cucim/requirements-test.txt
        fi
    fi
    hash -r
}

test_python_desc() { echo 'Execute Python test cases

Arguments:
  $1 - test_type [all|unit|integration|system|performance] (default: all)
  $2 - test_component [all|clara|skimage] (default: all)
'
}
test_python() {
    local test_type="${1:-all}"
    local test_component="${2:-all}"
    local result=0

    local testsuite=""
    local testsuite_unit_skimage="src"
    local testsuite_unit_clara="tests/unit"
    local testsuite_performance="tests/performance"

    install_python_test_deps_

    if [ "$test_type" = "all" ] || [ "$test_type" = "unit" ]; then
        local testsuite="${testsuite_unit_skimage} ${testsuite_unit_clara}"
        [ "$test_component" = "skimage" ] && testsuite="${testsuite_unit_skimage}"
        [ "$test_component" = "clara" ] && testsuite="${testsuite_unit_clara}"

    fi
    if [ "$test_type" = "all" ] || [ "$test_type" = "performance" ]; then
        testsuite="${testsuite} ${testsuite_performance}"
    fi

    pushd $TOP/python/cucim
    run_command py.test --cache-clear -vv \
        --cov=cucim \
        --junitxml="$TOP/junit-cucim.xml" \
        --cov-config=$TOP/python/cucim/.coveragerc \
        --cov-report=xml:"$TOP/cucim-coverage.xml" \
        --cov-report term \
        ${testsuite}
    result=$?
    popd

    return $result
}


#==================================================================================
# Section: Example
#==================================================================================

download_testdata_desc() { echo 'Download test data from Docker Hub
'
}
download_testdata() {
    c_echo W "Downloading test data..."
    run_command mkdir -p ${TOP}/notebooks/input
    if [ ! -e ${TOP}/notebooks/input/image.tif ]; then
        run_command rm -rf ${TOP}/notebooks/input
        id=$(docker create gigony/svs-testdata:little-big)
        run_command docker cp $id:/input ${TOP}/notebooks
        run_command docker rm -v $id
        c_echo G "Test data is downloaded to ${TOP}/notebooks/input!"
    else
        c_echo G "Test data already exists at ${TOP}/notebooks/input!"
    fi
}

launch_notebooks_desc() { echo 'Launch jupyter notebooks

Arguments:
  -p <port>                - port number
  -h <host>                - hostname to serve documentation on (default: 0.0.0.0)
  -g <path to NVMe device> - launch GDS-enabled container
'
}
launch_notebooks() {
    local OPTIND
    local port=$(get_unused_ports 1 10000 10030)
    local host='0.0.0.0'
    local gds_postfix=''
    local gds_nvme_path=''

    while getopts 'p:h:g:' option;
    do
        case "${option}" in
            p)
                port="$OPTARG"
                ;;
            h)
                host="$OPTARG"
                ;;
            g)
                gds_postfix='-gds'
                [ -z "$OPTARG" ] && c_echo_err R "Please specify NVMe path!" && return 1
                gds_nvme_path=$(readlink -f "$OPTARG")
                [ ! -d "$gds_nvme_path" ] && c_echo_err R "Folder $gds_nvme_path doesn't exist!" && return 1

                # Copy cufile SDK from host system to temp/cuda
                copy_gds_files_
                ;;
            *)
                return 1
       esac
    done
    shift $((OPTIND-1))

    download_testdata

    run_command cp ${TOP}/dist/*.whl ${TOP}/notebooks

    run_command nvidia-docker build -t cucim-jupyter${gds_postfix} -f ${TOP}/docker/Dockerfile-jupyter${gds_postfix}-dev ${TOP}

    [ $? -ne 0 ] && return 1

    c_echo W "Port " G "$port" W " would be used...(" B "http://$(hostname -I | cut -d' ' -f 1):${port}" W ")"

    if [ -z "${gds_postfix}" ]; then
        run_command nvidia-docker run --gpus all -it --rm \
            -v ${TOP}/notebooks:/notebooks \
            -p ${port}:${port} \
            cucim-jupyter \
            -c "echo -n 'Enter New Password: '; jupyter lab --ServerApp.password=\"\$(python3 -u -c \"from jupyter_server.auth import passwd;pw=input();print(passwd(pw));\" | egrep 'sha|argon')\" --ServerApp.root_dir=/notebooks --allow-root --port=${port} --ip=${host} --no-browser"
    else
        local MNT_PATH=/nvme
        local GDS_IMAGE=cucim-jupyter${gds_postfix}

        local BUILD_VER=`uname -r`
        local NV_DRIVER=`nvidia-smi -q -i 0 | sed -n 's/Driver Version.*: *\(.*\) *$/\1/p'`
        echo "using nvidia driver version $NV_DRIVER on kernel $BUILD_VER"

        local ofed_version=$(ofed_info -s | grep MLNX)
        if [ $? -eq 0 ]; then
            local rdma_core=$(dpkg -s libibverbs-dev | grep "Source: rdma-core")
            if [ $? -eq 0 ]; then
                local CONFIG_MOFED_VERSION=$(echo $ofed_version | cut -d '-' -f 2)
                echo "Found MOFED version $CONFIG_MOFED_VERSION"
            fi
            local MLNX_SRCS="--volume /usr/src/mlnx-ofed-kernel-${CONFIG_MOFED_VERSION}:/usr/src/mlnx-ofed-kernel-${CONFIG_MOFED_VERSION}:ro"
            local MOFED_DEVS="--net=host --volume /sys/class/infiniband_verbs:/sys/class/infiniband_verbs/ "
        fi

        docker run \
            --ipc host \
            -it \
            --rm \
            --gpus all \
            -v ${TOP}/notebooks:/notebooks \
            -p ${port}:${port} \
            --volume /run/udev:/run/udev:ro \
            --volume /sys/kernel/config:/sys/kernel/config/ \
            --volume /usr/src/nvidia-$NV_DRIVER:/usr/src/nvidia-$NV_DRIVER:ro  ${MLNX_SRCS}\
            --volume /dev:/dev:ro \
            --privileged \
            --env NV_DRIVER=${NV_DRIVER} \
            --volume /lib/modules/$BUILD_VER/:/lib/modules/$BUILD_VER \
            --volume "${MNT_PATH}:/notebooks/nvme:rw" \
            ${MOFED_DEVS} \
            ${GDS_IMAGE} \
            -c "echo -n 'Enter New Password: '; jupyter lab --ServerApp.password=\"\$(python3 -u -c \"from jupyter_server.auth import passwd;pw=input();print(passwd(pw));\" | egrep 'sha|argon')\" --ServerApp.root_dir=/notebooks --allow-root --port=${port} --ip=${host} --no-browser"
    fi

}

#==================================================================================
# Section: Documentation
#==================================================================================

install_tox_() {
    if ! command -v tox > /dev/null; then
        c_echo G "tox" W " doesn't exists. Installing " G "tox" W "..."
        if [ -n "${CONDA_PREFIX}" ]; then
            run_command pip3 install tox
        else
            if [ -n "${VIRTUAL_ENV}" ]; then
                run_command pip3 install tox
            else
                run_command pip3 install --user tox
            fi
        fi
        hash -r
    fi
}

gen_docs_desc() { echo 'Generate document

Generated docs would be avaialable at ${TOP}/dist/docs.

Returns:
  None

  Exit code:
    exit code returned from generating document
'
}
gen_docs() {
    local OUTPUT_FOLDER=${1:-${TOP}/dist/docs}
    local ret=0
    pushd ${TOP}/python/cucim > /dev/null

    # Install prerequisites
    install_tox_

    # Remove existing files in dist/docs
    run_command rm -rf ${OUTPUT_FOLDER}/*

    # Copy notebook files to python/cucim/dist/docs/notebooks
    run_command mkdir -p ${TOP}/python/cucim/docs/notebooks
    run_command rm -rf ${TOP}/python/cucim/docs/notebooks/*
    run_command mkdir -p ${TOP}/python/cucim/docs/notebooks/static_images
    run_command cp -r $(git ls-files ${TOP}/notebooks/*.ipynb) ${TOP}/python/cucim/docs/notebooks/
    run_command cp -r ${TOP}/notebooks/static_images/*.png ${TOP}/python/cucim/docs/notebooks/static_images/

    tox -e docs -- ${OUTPUT_FOLDER}
    ret=$?
    # Remove jupyter_execute folder explicitly until the issue is solved
    #   https://github.com/executablebooks/MyST-NB/issues/129
    rm -rf $(dirname ${OUTPUT_FOLDER})/jupyter_execute

    popd > /dev/null
    return $ret
}

gen_docs_dev_desc() { echo 'Generate document

Launch dev-server for sphinx.

Generated docs would be avaialable at ${TOP}/python/cucim/dist/docs.

Arguments:
  -p <port> - port number
  -h <host> - hostname to serve documentation on (default: 0.0.0.0)
Returns:
  None

  Exit code:
    exit code returned from generating document
'
}
gen_docs_dev() {
    local OPTIND
    local port=9999
    local host=0.0.0.0

    while getopts 'p:h:' option;
    do
        case "${option}" in
            p)
                port="$OPTARG"
                ;;
            h)
                host="$OPTARG"
                ;;
            *)
                echo_err R "Invalid option!"
                return 1
        esac
    done

    pushd ${TOP}/python/cucim > /dev/null

    # Install prerequisites
    install_tox_

    # Remove existing files in python/cucim/dist/docs
    run_command rm -rf ${TOP}/python/cucim/dist/docs/*
    # Copy notebook files to python/cucim/dist/docs/notebooks
    run_command mkdir -p ${TOP}/python/cucim/docs/notebooks/static_images
    run_command rm -rf ${TOP}/python/cucim/docs/notebooks/*
    run_command cp -r $(git ls-files ${TOP}/notebooks/*.ipynb) ${TOP}/python/cucim/docs/notebooks/
    run_command cp -r ${TOP}/notebooks/static_images/*.png ${TOP}/python/cucim/docs/notebooks/static_images/

    run_command tox -e docs-dev -- --port ${port} --host ${host} docs dist/docs
    popd > /dev/null
}

publish_docs_desc() { echo 'Publish generated documents to the server

Publish generated documents to $GITLAB_PUBLISH_PROJECT_URL
The web page is available at the followings:
- $GITLAB_PUBLISH_PROJECT_URL

Arguments:
  $1 - If specified, force creating a tag with the specified tag name.
       Use "latest" tag to make public documents up to date.

Returns:
  None

  Exit code:
    exit code returned from publishing documents
'
}
publish_docs() {
    local release_version="$(cat ${TOP}/VERSION)"
    local release_tag="${1:-v${release_version}}"

    # Import secrets
    import_env_vars_ || return 1

    c_echo W "Publishing documents to Gitlab Pages..."
    TEMP_DOCS_DIR=$(mktemp -d)
    c_echo r "TEMP_DOCS_DIR=${TEMP_DOCS_DIR}"
    trap 'rm -rf ${TEMP_DOCS_DIR}' EXIT

    pushd ${TEMP_DOCS_DIR} > /dev/null

    git clone ${GITLAB_PUBLISH_GIT_URL} --branch init --single-branch
    cd ${GITLAB_PUBLISH_PROJECT_NAME}
    mkdir -p dist/docs
    cp -rf ${TOP}/dist/docs/* dist/docs/
    git checkout -b pages
    git add dist/docs
    git commit -am "Upload home page v$(cat ${TOP}/VERSION)"
    git tag -f ${release_tag}
    git push -f origin pages
    git push -f origin ${release_tag}
    popd > /dev/null

    # Create tag if custom (such as 'latest') tag is specified
    if [ -n "${1:-}" ]; then
        git tag -f "$1"
        git push -f origin "$1"
    fi

    run_command rm -rf ${TEMP_DOCS_DIR}
    trap -- EXIT

    c_echo W "Checkout the published webpage!"
}

#==================================================================================
# Section: Release
#==================================================================================

update_version_desc() { echo 'Update version

Executes ci/release/update-version.sh which updates some version-related
files based on VERSION file.

Returns:
  Outputs executed by update-version.sh

  Exit code:
    exit code returned from update-version.sh
'
}
update_version() {
    local new_version=${1:-}
    local ret=0
    [ -z "${new_version}" ] && c_echo_err R "Please specify '[new version]' (e.g., '21.06.00')!" && return 1
    $TOP/ci/release/update-version.sh "$@"
    ret=$?

    return $ret
}

import_env_vars_() {
    if [ ! -e ${TOP}/.env ]; then
        c_echo_err "File " G "${TOP}/.env " Z "is not found.\n" R \
        "Please create the file with the following environment variable!"
        c_echo_err " - " W "GITLAB_ACCESS_TOKEN"
        c_echo_err " - " W "GITLAB_PUBLISH_SERVER"
        c_echo_err " - " W "GITLAB_PUBLISH_PROJECT_NAME"
        c_echo_err " - " W "GITLAB_PUBLISH_PROJECT_ID"
        c_echo_err " - " W "GITLAB_PUBLISH_PROJECT_URL"
        c_echo_err " - " W "GITLAB_PUBLISH_GIT_URL"
        return 1
    fi

    # Import environment variables
    . ${TOP}/.env
}
release_package_desc() { echo 'Release generated packages to the server

Release generated package files to $GITLAB_PUBLISH_PROJECT_URL
This leverages "release" environment in tox and uses
  https://gitlab.com/alelec/gitlab-release
for uploading files to the server.

Returns:
  None

  Exit code:
    exit code returned from releasing packages
'
}
release_package() {
    local release_version="$(cat ${TOP}/VERSION)"
    local release_tag="v${release_version}"
    local wheel_file_name="cucim-${release_version}-py3-none-manylinux2014_x86_64.whl"
    local package_file_name="cuCIM-${release_tag}-linux.tar.gz"
    local package_data
    local release_note_md="${TOP}/python/cucim/docs/release_notes/${release_tag}.md"

    # Import secrets
    import_env_vars_ || return 1

    # Publish docs first to create a release tag
    publish_docs

    old_opt="$(shopt -op errexit);$(shopt -op nounset)" # save old shopts
    set -eu
    trap 'eval "${old_opt}"; unset old_opt' EXIT

    pushd ${TOP}/python/cucim/ > /dev/null

    # https://github.com/gitlabhq/gitlabhq/blob/master/doc/api/releases/index.md
    # https://docs.gitlab.com/ee/api/releases/index.html#delete-a-release

    # install jq if not exists
    if ! command -v jq > /dev/null; then
        c_echo G "jq" W " doesn't exists. Installing " G "jq" W "..."
        sudo apt-get install -y jq
        hash -r
    fi

    if curl --silent --header "PRIVATE-TOKEN: ${GITLAB_ACCESS_TOKEN}" "${GITLAB_PUBLISH_SERVER}/api/v4/projects/${GITLAB_PUBLISH_PROJECT_ID}/releases/${release_tag}" | jq '.name' -e > /dev/null; then
        read -n 1 -r -p "$(c_str R "Do you want to delete existing release " G "${release_tag}" R " (y/n)?")"
        echo
        if [[ $REPLY =~ ^[Yy]$ ]]
        then
            c_echo W "Removing release " G "${release_tag}..."
            curl --request DELETE --header "PRIVATE-TOKEN: ${GITLAB_ACCESS_TOKEN}" "${GITLAB_PUBLISH_SERVER}/api/v4/projects/${GITLAB_PUBLISH_PROJECT_ID}/releases/${release_tag}" | jq
        else
            return
        fi
    fi

    run_command cd ${TOP}/dist
    run_command rm -rf ${package_file_name}
    run_command tar -czvf ${package_file_name} --exclude='*.gz' ./* ./.dockerignore  # --exclude="*.whl"
    package_url="${GITLAB_PUBLISH_SERVER}$(curl --request POST \
        --header "PRIVATE-TOKEN: ${GITLAB_ACCESS_TOKEN}" \
        --form "file=@${package_file_name}" \
        "${GITLAB_PUBLISH_SERVER}/api/v4/projects/${GITLAB_PUBLISH_PROJECT_ID}/uploads" \
        | jq '.full_path' -r)"

    wheel_url="${GITLAB_PUBLISH_SERVER}$(curl --request POST \
        --header "PRIVATE-TOKEN: ${GITLAB_ACCESS_TOKEN}" \
        --form "file=@${wheel_file_name}" \
        "${GITLAB_PUBLISH_SERVER}/api/v4/projects/${GITLAB_PUBLISH_PROJECT_ID}/uploads" \
        | jq '.full_path' -r)"

    package_data="$(echo "
import json
release_note = open('${release_note_md}').read()
data = {'tag_name': '${release_tag}',
        'description': release_note,
        'assets': {
            'links': [
                {'name': '${package_file_name}',
                 'url': '${package_url}'
                },
                {'name': '${wheel_file_name}',
                 'url': '${wheel_url}'
                }
            ]
        }
    }
print(json.dumps(data))
" | python -)"
    c_echo b "${package_data}"

    # Force-push tag
    git tag -f ${release_tag} && git push -f origin ${release_tag}

    # https://docs.gitlab.com/ee/api/releases/#create-a-release
    curl --header 'Content-Type: application/json' --header "PRIVATE-TOKEN: ${GITLAB_ACCESS_TOKEN}" \
        --data "${package_data}" \
        --request POST "${GITLAB_PUBLISH_SERVER}/api/v4/projects/${GITLAB_PUBLISH_PROJECT_ID}/releases" | jq

    popd > /dev/null

    # tox -c ${TOP}/python/cucim -e release -- ${TOP}/run release_package_to_gitlab

    eval "${old_opt}" # restore old shopts
    trap -- EXIT
    unset old_opt
}

parse_args() {
    local OPTIND
    while getopts 'yh' option;
    do
        case "${option}" in
            # a)
            #     VALUE=${OPTARG}
            #     ;;
            y)
                ALWAYS_YES=true;
                ;;
            h)
                print_usage
                exit 1
                ;;
            *)
                ;;
        esac
    done
    shift $((OPTIND-1))

    CMD="$1"
    shift

    ARGS=("$@")
}

print_usage() {
    set +x
    echo_err
    echo_err "USAGE: $0 [command] [arguments]..."
    echo_err ""
    c_echo_err W "Global Arguments"
    echo_err
    c_echo_err W "Command List"
    c_echo_err Y "    help  " w "----------------------------  Print detailed description for a given argument (command name)"
    echo_err "$(get_list_of_available_commands "${RUN_SCRIPT_FILE}" | my_cat_prefix " ")"
    echo_err
}

print_cmd_help_messages() {
    local cmd="$1"
    if [ -n "${cmd}" ]; then
        if type ${cmd}_desc > /dev/null 2>&1; then
            ${cmd}_desc
            exit 0
        else
            c_echo_err R "Command '${cmd}' doesn't exist!"
            exit 1
        fi
    fi
    print_usage
    return 0
}

main() {
    local ret=0
    parse_args "$@"

    case "$CMD" in
        help)
            print_cmd_help_messages "${ARGS[@]}"
            exit 0
            ;;
        package)
            build_package "${ARGS[@]}"
            ;;
        notebooks)
            launch_notebooks "${ARGS[@]}"
            ;;
        docs)
            gen_docs "${ARGS[@]}"
            ;;
        docs:dev)
            gen_docs_dev "${ARGS[@]}"
            ;;
        release)
            release_package "${ARGS[@]}"
            ;;
        ''|main)
            print_usage
            ;;
        *)
            if type ${CMD} > /dev/null 2>&1; then
                "$CMD" "${ARGS[@]}"
            else
                print_usage
                exit 1
            fi
            ;;
    esac
    ret=$?
    if [ -n "${SCRIPT_DIR}" ]; then
        exit $ret
    fi
}

init_globals

if [ -n "${SCRIPT_DIR}" ]; then
    main "$@"
fi


# Description template

# Globals:
#   CS_OS
#   CS_TARGET
#   CS_USER (used if CS_OS is "l4t")
#   CS_HOST (used if CS_OS is "l4t")
#   CS_OBSCURA_MODE (used in Obscura server)
# Arguments:
#   Command line to execute
# Returns:
#   Outputs print messages during the execution (stdout->stdout, stderr->stderr).

#   Note:
#     This command removes "\r" characters from stdout.

#   Exit code:
#     exit code returned from executing a given command
